{
	"name": "DeepLearning - Flower Image Classification",
	"properties": {
		"folder": {
			"name": "other"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "ad40e5a0-3693-4c2f-8f30-8affa749b28f"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1"
			},
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"## Deep Learning - Flower Image Classification"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from pyspark.ml import Transformer, Estimator, Pipeline\n",
					"from pyspark.ml.classification import LogisticRegression\n",
					"from synapse.ml.downloader import ModelDownloader\n",
					"import os, sys, time"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"mml-deploy": "local"
				},
				"source": [
					"model = ModelDownloader(spark, \"dbfs:/models/\").downloadByName(\"ResNet50\")"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Load the images\n",
					"# use flowers_and_labels.parquet on larger cluster in order to get better results\n",
					"imagesWithLabels = spark.read.parquet(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/flowers_and_labels2.parquet\") \\\n",
					"    .withColumnRenamed(\"bytes\",\"image\").sample(.1)\n",
					"\n",
					"imagesWithLabels.printSchema()"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"![Smiley face](https://i.imgur.com/p2KgdYL.jpg)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from synapse.ml.opencv import ImageTransformer\n",
					"from synapse.ml.image import UnrollImage\n",
					"from synapse.ml.cntk import ImageFeaturizer\n",
					"from synapse.ml.stages import *\n",
					"\n",
					"# Make some featurizers\n",
					"it = ImageTransformer()\\\n",
					"    .setOutputCol(\"scaled\")\\\n",
					"    .resize(size=(60, 60))\n",
					"\n",
					"ur = UnrollImage()\\\n",
					"    .setInputCol(\"scaled\")\\\n",
					"    .setOutputCol(\"features\")\n",
					"    \n",
					"dc1 = DropColumns().setCols([\"scaled\", \"image\"])\n",
					"\n",
					"lr1 = LogisticRegression().setMaxIter(8).setFeaturesCol(\"features\").setLabelCol(\"labels\")\n",
					"\n",
					"dc2 = DropColumns().setCols([\"features\"])\n",
					"\n",
					"basicModel = Pipeline(stages=[it, ur, dc1, lr1, dc2])"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"resnet = ImageFeaturizer()\\\n",
					"    .setInputCol(\"image\")\\\n",
					"    .setOutputCol(\"features\")\\\n",
					"    .setModelLocation(model.uri)\\\n",
					"    .setLayerNames(model.layerNames)\\\n",
					"    .setCutOutputLayers(1)\n",
					"    \n",
					"dc3 = DropColumns().setCols([\"image\"])\n",
					"    \n",
					"lr2 = LogisticRegression().setMaxIter(8).setFeaturesCol(\"features\").setLabelCol(\"labels\")\n",
					"\n",
					"dc4 = DropColumns().setCols([\"features\"])\n",
					"\n",
					"deepModel = Pipeline(stages=[resnet, dc3, lr2, dc4])    "
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"![Resnet 18](https://i.imgur.com/Mb4Dyou.png)"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"### How does it work?\n",
					"\n",
					"![Convolutional network weights](http://i.stack.imgur.com/Hl2H6.png)"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Run the experiment"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"def timedExperiment(model, train, test):\n",
					"  start = time.time()\n",
					"  result =  model.fit(train).transform(test).toPandas()\n",
					"  print(\"Experiment took {}s\".format(time.time() - start))\n",
					"  return result"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"train, test = imagesWithLabels.randomSplit([.8,.2])\n",
					"train.count(), test.count()"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"basicResults = timedExperiment(basicModel, train, test)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"deepResults = timedExperiment(deepModel, train, test)"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Plot confusion matrix."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"import matplotlib.pyplot as plt\n",
					"from sklearn.metrics import confusion_matrix\n",
					"import numpy as np\n",
					"\n",
					"def evaluate(results, name):\n",
					"    y, y_hat = results[\"labels\"],results[\"prediction\"]\n",
					"    y = [int(l) for l in y]\n",
					"\n",
					"    accuracy = np.mean([1. if pred==true else 0. for (pred,true) in zip(y_hat,y)])\n",
					"    cm = confusion_matrix(y, y_hat)\n",
					"    cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
					"\n",
					"    plt.text(40, 10,\"$Accuracy$ $=$ ${}\\%$\".format(round(accuracy*100,1)),fontsize=14)\n",
					"    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
					"    plt.colorbar()\n",
					"    plt.xlabel(\"$Predicted$ $label$\", fontsize=18)\n",
					"    plt.ylabel(\"$True$ $Label$\", fontsize=18)\n",
					"    plt.title(\"$Normalized$ $CM$ $for$ ${}$\".format(name))\n",
					"\n",
					"plt.figure(figsize=(12,5))\n",
					"plt.subplot(1,2,1)\n",
					"evaluate(deepResults,\"CNTKModel + LR\")\n",
					"plt.subplot(1,2,2)\n",
					"evaluate(basicResults,\"LR\")\n",
					"# Note that on the larger dataset the accuracy will bump up from 44% to >90%\n",
					"display(plt.show())"
				]
			}
		]
	}
}